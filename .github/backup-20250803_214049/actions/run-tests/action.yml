name: 'Run Tests'
description: 'Runs Go tests with coverage, race detection, and comprehensive error recovery'

inputs:
  test-type:
    description: 'Type of tests to run (unit, integration, all)'
    required: false
    default: 'all'
  race-detection:
    description: 'Enable race detection'
    required: false
    default: 'true'
  coverage:
    description: 'Enable coverage reporting'
    required: false
    default: 'true'
  timeout:
    description: 'Test timeout'
    required: false
    default: '10m'
  max-retries:
    description: 'Maximum number of retries for flaky tests'
    required: false
    default: '2'
  fail-fast:
    description: 'Stop on first test failure (false allows partial success)'
    required: false
    default: 'false'
  package-isolation:
    description: 'Run tests in package isolation mode'
    required: false
    default: 'true'
  continue-on-failure:
    description: 'Continue pipeline even if some tests fail'
    required: false
    default: 'true'
  parallelism:
    description: 'Number of parallel test processes'
    required: false
    default: '2'

outputs:
  coverage-report:
    description: 'Path to coverage report'
    value: ${{ steps.test.outputs.coverage-report }}
  test-success:
    description: 'Overall test success status'
    value: ${{ steps.test-execution.outputs.success }}
  tests-run:
    description: 'Number of tests executed'
    value: ${{ steps.test-execution.outputs.tests-run }}
  tests-passed:
    description: 'Number of tests that passed'
    value: ${{ steps.test-execution.outputs.tests-passed }}
  tests-failed:
    description: 'Number of tests that failed'
    value: ${{ steps.test-execution.outputs.tests-failed }}
  packages-tested:
    description: 'Number of packages tested'
    value: ${{ steps.test-execution.outputs.packages-tested }}
  retry-count:
    description: 'Number of retries used'
    value: ${{ steps.test-execution.outputs.retry-count }}
  partial-success:
    description: 'Whether partial success was achieved'
    value: ${{ steps.test-execution.outputs.partial-success }}

runs:
  using: 'composite'
  steps:
    - name: Setup reliability framework
      shell: bash
      run: |
        # Source reliability script or create minimal fallback
        if [[ -f "${{ github.workspace }}/.github/scripts/ci-reliability.sh" ]]; then
          source "${{ github.workspace }}/.github/scripts/ci-reliability.sh"
        else
          log_info() { echo "ℹ️  $1"; }
          log_warn() { echo "⚠️  $1" >&2; }
          log_error() { echo "❌ $1" >&2; }
          log_debug() { echo "🔍 $1"; }
        fi
        
        echo "🔧 Setting up test execution environment"
        
        # Create test results directory
        mkdir -p test-results
        
        # Initialize test tracking files
        echo "0" > test-results/total-tests
        echo "0" > test-results/passed-tests  
        echo "0" > test-results/failed-tests
        echo "0" > test-results/packages-tested
        echo "0" > test-results/retry-count
        echo "" > test-results/failed-packages
        
        log_info "Test environment prepared"

    - name: Install test tools with retry
      shell: bash
      run: |
        source "${{ github.workspace }}/.github/scripts/ci-reliability.sh" 2>/dev/null || true
        
        echo "🔧 Installing test and analysis tools with retry mechanism"
        
        # Function to install Go tools with retry
        install_go_tool() {
          local tool_name="$1"
          local tool_path="$2"
          
          echo "Installing $tool_name..."
          for attempt in {1..3}; do
            if timeout 300 go install "$tool_path"; then
              echo "✅ $tool_name installed successfully"
              return 0
            else
              echo "⚠️ Failed to install $tool_name (attempt $attempt/3)"
              if [[ $attempt -lt 3 ]]; then
                sleep $((attempt * 5))
              fi
            fi
          done
          
          echo "❌ Failed to install $tool_name after 3 attempts"
          return 1
        }
        
        # Install tools with retry
        install_go_tool "gosec" "github.com/securego/gosec/v2/cmd/gosec@latest" || echo "gosec installation failed, will skip security scan"
        install_go_tool "staticcheck" "honnef.co/go/tools/cmd/staticcheck@latest" || echo "staticcheck installation failed, will skip static analysis"
        
        echo "✅ Tool installation completed"

    - name: Discover test packages
      id: discover-packages
      shell: bash
      run: |
        source "${{ github.workspace }}/.github/scripts/ci-reliability.sh" 2>/dev/null || true
        
        echo "🔍 Discovering test packages"
        
        # Find all packages with tests
        packages=()
        
        case "${{ inputs.test-type }}" in
          "unit")
            echo "Discovering unit test packages..."
            while IFS= read -r package; do
              if [[ -n "$package" ]]; then
                packages+=("$package")
              fi
            done < <(go list -f '{{if .TestGoFiles}}{{.ImportPath}}{{end}}' ./... 2>/dev/null || true)
            ;;
          "integration") 
            echo "Discovering integration test packages..."
            while IFS= read -r package; do
              if [[ -n "$package" ]]; then
                # Check if package has integration tests
                if grep -r "Integration" "$(go list -f '{{.Dir}}' "$package" 2>/dev/null)"/*_test.go 2>/dev/null | head -1 >/dev/null; then
                  packages+=("$package")
                fi
              fi
            done < <(go list -f '{{if .TestGoFiles}}{{.ImportPath}}{{end}}' ./... 2>/dev/null || true)
            ;;
          "all"|*)
            echo "Discovering all test packages..."
            while IFS= read -r package; do
              if [[ -n "$package" ]]; then
                packages+=("$package")
              fi
            done < <(go list -f '{{if .TestGoFiles}}{{.ImportPath}}{{end}}' ./... 2>/dev/null || true)
            ;;
        esac
        
        echo "Found ${#packages[@]} packages with tests"
        
        # Save package list for later steps
        printf '%s\n' "${packages[@]}" > test-results/packages-to-test
        echo "${#packages[@]}" > test-results/packages-total
        
        log_info "Package discovery completed: ${#packages[@]} packages found"

    - name: Execute tests with isolation and retry
      id: test-execution
      shell: bash
      run: |
        source "${{ github.workspace }}/.github/scripts/ci-reliability.sh" 2>/dev/null || true
        
        echo "🧪 Executing tests with enhanced reliability"
        
        # Initialize counters
        total_tests=0
        passed_tests=0 
        failed_tests=0
        packages_tested=0
        retry_count=0
        overall_success=true
        partial_success=false
        
        # Test execution flags
        TEST_FLAGS="-v -timeout=${{ inputs.timeout }}"
        
        if [[ "${{ inputs.race-detection }}" == "true" ]]; then
          TEST_FLAGS="$TEST_FLAGS -race"
        fi
        
        if [[ "${{ inputs.coverage }}" == "true" ]]; then
          TEST_FLAGS="$TEST_FLAGS -coverprofile=coverage.out -covermode=atomic"
          echo "coverage-report=coverage.out" >> $GITHUB_OUTPUT
        fi
        
        # Read packages to test
        packages=()
        if [[ -f "test-results/packages-to-test" ]]; then
          while IFS= read -r package; do
            if [[ -n "$package" ]]; then
              packages+=("$package")
            fi
          done < test-results/packages-to-test
        fi
        
        if [[ ${#packages[@]} -eq 0 ]]; then
          echo "⚠️ No test packages found, running basic test discovery"
          packages=("./...")
        fi
        
        # Function to run tests for a single package
        run_package_tests() {
          local package="$1"
          local attempt="$2"
          
          echo "📦 Testing package: $package (attempt $attempt)"
          
          local test_output
          local test_exit_code
          
          # Adjust test pattern based on test type
          local test_pattern=""
          case "${{ inputs.test-type }}" in
            "unit")
              test_pattern="-short"
              ;;
            "integration")
              test_pattern="-run Integration"
              ;;
          esac
          
          # Run the test with timeout
          if test_output=$(timeout ${{ inputs.timeout }} go test $TEST_FLAGS $test_pattern "$package" 2>&1); then
            test_exit_code=0
          else
            test_exit_code=$?
          fi
          
          # Parse test results from output
          local package_tests=0
          local package_passed=0
          local package_failed=0
          
          # Extract test counts from go test output
          if echo "$test_output" | grep -q "PASS\|FAIL"; then
            package_tests=$(echo "$test_output" | grep -c "=== RUN" || echo "0")
            if [[ $test_exit_code -eq 0 ]]; then
              package_passed=$package_tests
            else
              # Try to count individual test results
              package_passed=$(echo "$test_output" | grep -c "--- PASS:" || echo "0")
              package_failed=$(echo "$test_output" | grep -c "--- FAIL:" || echo "0")
              if [[ $((package_passed + package_failed)) -eq 0 ]] && [[ $package_tests -gt 0 ]]; then
                # Fallback: assume all tests failed if we can't parse individual results
                package_failed=$package_tests
              fi
            fi
          fi
          
          echo "Package results: tests=$package_tests, passed=$package_passed, failed=$package_failed, exit_code=$test_exit_code"
          
          # Update counters
          total_tests=$((total_tests + package_tests))
          passed_tests=$((passed_tests + package_passed))
          failed_tests=$((failed_tests + package_failed))
          
          return $test_exit_code
        }
        
        # Function to test a package with retry logic
        test_package_with_retry() {
          local package="$1"
          local max_retries="${{ inputs.max-retries }}"
          
          for attempt in $(seq 1 $((max_retries + 1))); do
            if run_package_tests "$package" "$attempt"; then
              echo "✅ Package $package passed on attempt $attempt"
              packages_tested=$((packages_tested + 1))
              return 0
            else
              if [[ $attempt -le $max_retries ]]; then
                echo "⚠️ Package $package failed on attempt $attempt, retrying..."
                retry_count=$((retry_count + 1))
                sleep $((attempt * 2))
              else
                echo "❌ Package $package failed after $((max_retries + 1)) attempts"
                echo "$package" >> test-results/failed-packages
                
                if [[ "${{ inputs.continue-on-failure }}" == "true" ]]; then
                  echo "🔄 Continuing with next package due to continue-on-failure setting"
                  packages_tested=$((packages_tested + 1))
                  partial_success=true
                  return 1
                else
                  if [[ "${{ inputs.fail-fast }}" == "true" ]]; then
                    echo "🛑 Stopping test execution due to fail-fast setting"
                    return 1
                  fi
                fi
              fi
            fi
          done
          
          return 1
        }
        
        # Execute tests
        if [[ "${{ inputs.package-isolation }}" == "true" ]] && [[ ${#packages[@]} -gt 1 ]]; then
          echo "🔬 Running tests in package isolation mode"
          
          for package in "${packages[@]}"; do
            if ! test_package_with_retry "$package"; then
              if [[ "${{ inputs.continue-on-failure }}" != "true" ]] && [[ "${{ inputs.fail-fast }}" == "true" ]]; then
                overall_success=false
                break
              fi
            fi
          done
        else
          echo "🚀 Running tests in batch mode"
          test_package_with_retry "${packages[*]}"
        fi
        
        # Determine overall success
        if [[ $failed_tests -gt 0 ]]; then
          if [[ "${{ inputs.continue-on-failure }}" == "true" ]]; then
            if [[ $passed_tests -gt 0 ]]; then
              partial_success=true
              echo "⚠️ Partial success: $passed_tests passed, $failed_tests failed"
            else
              overall_success=false
            fi
          else
            overall_success=false
          fi
        fi
        
        # Save results
        echo "$total_tests" > test-results/total-tests
        echo "$passed_tests" > test-results/passed-tests
        echo "$failed_tests" > test-results/failed-tests
        echo "$packages_tested" > test-results/packages-tested
        echo "$retry_count" > test-results/retry-count
        
        # Set outputs
        echo "success=$overall_success" >> $GITHUB_OUTPUT
        echo "tests-run=$total_tests" >> $GITHUB_OUTPUT
        echo "tests-passed=$passed_tests" >> $GITHUB_OUTPUT
        echo "tests-failed=$failed_tests" >> $GITHUB_OUTPUT
        echo "packages-tested=$packages_tested" >> $GITHUB_OUTPUT
        echo "retry-count=$retry_count" >> $GITHUB_OUTPUT
        echo "partial-success=$partial_success" >> $GITHUB_OUTPUT
        
        # Summary
        echo "📊 Test Execution Summary:"
        echo "   Total tests: $total_tests"
        echo "   Passed: $passed_tests"
        echo "   Failed: $failed_tests"
        echo "   Packages tested: $packages_tested"
        echo "   Retries used: $retry_count"
        echo "   Overall success: $overall_success"
        echo "   Partial success: $partial_success"
        
        # Determine exit code
        if [[ "$overall_success" == "true" ]] || [[ "$partial_success" == "true" && "${{ inputs.continue-on-failure }}" == "true" ]]; then
          exit 0
        else
          exit 1
        fi

    - name: Generate coverage report
      if: ${{ inputs.coverage == 'true' }}
      shell: bash
      run: |
        source "${{ github.workspace }}/.github/scripts/ci-reliability.sh" 2>/dev/null || true
        
        echo "📊 Generating coverage reports"
        
        if [[ -f coverage.out ]]; then
          echo "Generating HTML coverage report..."
          if go tool cover -html=coverage.out -o coverage.html; then
            echo "✅ HTML coverage report generated: coverage.html"
          else
            echo "⚠️ Failed to generate HTML coverage report"
          fi
          
          echo "Generating coverage summary..."
          if coverage_summary=$(go tool cover -func=coverage.out | tail -1); then
            echo "Coverage summary: $coverage_summary"
            
            # Extract coverage percentage
            coverage_pct=$(echo "$coverage_summary" | grep -o '[0-9]*\.[0-9]*%' || echo "0.0%")
            echo "COVERAGE_PERCENTAGE=$coverage_pct" >> $GITHUB_ENV
            
            echo "✅ Coverage analysis completed: $coverage_pct"
          else
            echo "⚠️ Failed to generate coverage summary"
          fi
        else
          echo "⚠️ No coverage file found, skipping coverage report generation"
        fi

    - name: Run security scan with isolation
      shell: bash
      run: |
        source "${{ github.workspace }}/.github/scripts/ci-reliability.sh" 2>/dev/null || true
        
        echo "🔒 Running security scan with fault isolation"
        
        if command -v gosec &> /dev/null; then
          echo "Running gosec security scanner..."
          
          # Run gosec with no-fail to prevent pipeline termination
          if gosec -no-fail -fmt sarif -out gosec-results.sarif ./... 2>/dev/null; then
            echo "✅ Security scan completed successfully"
          else
            echo "⚠️ Security scan completed with warnings"
            # Ensure SARIF file exists even with warnings
            if [[ ! -f gosec-results.sarif ]]; then
              echo '{"version":"2.1.0","$schema":"https://raw.githubusercontent.com/oasis-tcs/sarif-spec/master/Schemata/sarif-schema-2.1.0.json","runs":[{"tool":{"driver":{"name":"gosec","version":"latest"}},"results":[]}]}' > gosec-results.sarif
            fi
          fi
        else
          echo "⚠️ gosec not available, creating empty SARIF file"
          echo '{"version":"2.1.0","$schema":"https://raw.githubusercontent.com/oasis-tcs/sarif-spec/master/Schemata/sarif-schema-2.1.0.json","runs":[{"tool":{"driver":{"name":"gosec","version":"not-installed"}},"results":[]}]}' > gosec-results.sarif
        fi

    - name: Run static analysis with fault tolerance
      shell: bash
      run: |
        source "${{ github.workspace }}/.github/scripts/ci-reliability.sh" 2>/dev/null || true
        
        echo "🔍 Running static analysis with fault tolerance"
        
        if command -v staticcheck &> /dev/null; then
          echo "Running staticcheck static analyzer..."
          
          # Run staticcheck with timeout and continue on failure
          if timeout 300 staticcheck ./... 2>/dev/null; then
            echo "✅ Static analysis completed successfully"
          else
            echo "⚠️ Static analysis completed with issues or timed out"
            echo "Continuing pipeline execution..."
          fi
        else
          echo "⚠️ staticcheck not available, skipping static analysis"
        fi

    - name: Generate test summary report
      if: always()
      shell: bash
      run: |
        source "${{ github.workspace }}/.github/scripts/ci-reliability.sh" 2>/dev/null || true
        
        echo "📋 Generating comprehensive test summary"
        
        # Read test results
        total_tests=$(cat test-results/total-tests 2>/dev/null || echo "0")
        passed_tests=$(cat test-results/passed-tests 2>/dev/null || echo "0")
        failed_tests=$(cat test-results/failed-tests 2>/dev/null || echo "0")
        packages_tested=$(cat test-results/packages-tested 2>/dev/null || echo "0")
        retry_count=$(cat test-results/retry-count 2>/dev/null || echo "0")
        
        # Calculate success rate
        if [[ $total_tests -gt 0 ]]; then
          success_rate=$(echo "scale=2; $passed_tests * 100 / $total_tests" | bc -l 2>/dev/null || echo "0")
        else
          success_rate="0"
        fi
        
        # Generate GitHub step summary
        cat >> $GITHUB_STEP_SUMMARY << EOF
        ## Test Execution Report
        
        **Test Type**: ${{ inputs.test-type }}
        **Execution Mode**: ${{ inputs.package-isolation == 'true' && 'Package Isolation' || 'Batch Mode' }}
        **Race Detection**: ${{ inputs.race-detection }}
        **Coverage**: ${{ inputs.coverage }}
        
        ### Results Summary
        | Metric | Value |
        |--------|-------|
        | Total Tests | $total_tests |
        | Passed | $passed_tests |
        | Failed | $failed_tests |
        | Success Rate | ${success_rate}% |
        | Packages Tested | $packages_tested |
        | Retries Used | $retry_count |
        | Coverage | ${COVERAGE_PERCENTAGE:-"N/A"} |
        
        ### Configuration
        - **Max Retries**: ${{ inputs.max-retries }}
        - **Fail Fast**: ${{ inputs.fail-fast }}
        - **Continue on Failure**: ${{ inputs.continue-on-failure }}
        - **Timeout**: ${{ inputs.timeout }}
        
        EOF
        
        # Add failed packages if any
        if [[ -f "test-results/failed-packages" ]] && [[ -s "test-results/failed-packages" ]]; then
          echo "### Failed Packages" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          while IFS= read -r package; do
            echo "- \`$package\`" >> $GITHUB_STEP_SUMMARY
          done < test-results/failed-packages
          echo "" >> $GITHUB_STEP_SUMMARY
        fi
        
        # Add retry information if retries were used
        if [[ $retry_count -gt 0 ]]; then
          cat >> $GITHUB_STEP_SUMMARY << EOF
        ### Reliability Information
        - **Retries Used**: $retry_count
        - **Fault Tolerance**: Active
        - **Partial Success**: ${{ steps.test-execution.outputs.partial-success }}
        
        EOF
        fi
        
        echo "✅ Test summary report generated"