package server

import (
	"context"
	"fmt"
	"net/http"

	"freightliner/pkg/config"
	"freightliner/pkg/replication"
)

// Enhanced server methods for production features

// registerEnhancedEndpoints registers additional production-ready endpoints
func (s *Server) registerEnhancedEndpoints() {
	// API endpoints with versioning
	apiRouter := s.router.PathPrefix("/api/v1").Subrouter()

	// Add rate limiting middleware if enabled
	if s.cfg.Server.RateLimit > 0 {
		apiRouter.Use(s.rateLimitMiddleware)
	}

	// Add CORS middleware if enabled
	if s.cfg.Server.EnableCORS {
		apiRouter.Use(s.corsMiddleware)
	}

	// Add API key authentication middleware if enabled
	if s.cfg.Server.APIKeyAuth {
		apiRouter.Use(s.apiKeyMiddleware)
	}

	// Enhanced job management endpoints
	apiRouter.HandleFunc("/jobs/{id}/cancel", s.cancelJobHandler).Methods("DELETE", "POST")
	apiRouter.HandleFunc("/jobs/{id}/retry", s.retryJobHandler).Methods("POST")

	// Registry management endpoints
	apiRouter.HandleFunc("/registries", s.listRegistriesHandler).Methods("GET")
	apiRouter.HandleFunc("/registries/{name}/health", s.getRegistryHealthHandler).Methods("GET")

	// System status endpoints
	apiRouter.HandleFunc("/system/health", s.getSystemHealthHandler).Methods("GET")
	apiRouter.HandleFunc("/system/stats", s.getWorkerPoolStatsHandler).Methods("GET")

	// Checkpoint management (already exists in main server.go)
	// apiRouter.HandleFunc("/checkpoints", s.listCheckpointsHandler).Methods("GET")
	// apiRouter.HandleFunc("/checkpoints/{id}", s.getCheckpointHandler).Methods("GET")
	// apiRouter.HandleFunc("/checkpoints/{id}", s.deleteCheckpointHandler).Methods("DELETE")
}

// Enhanced worker pool with auto-scaling support
func (s *Server) createEnhancedWorkerPool(workerCount int) *replication.WorkerPool {
	// Create base worker pool
	pool := replication.NewWorkerPool(workerCount, s.logger)

	// Initialize auto-scaler if enabled
	if s.cfg.Workers.AutoScale {
		minWorkers := s.cfg.Workers.MinWorkers
		maxWorkers := s.cfg.Workers.MaxWorkers

		if minWorkers <= 0 {
			minWorkers = 1
		}
		if maxWorkers <= 0 {
			maxWorkers = workerCount * 2
		}

		autoScalerConfig := replication.AutoScalerConfig{
			MinWorkers:      minWorkers,
			MaxWorkers:      maxWorkers,
			ScaleUpThresh:   0.7, // Scale up when queue is 70% full
			ScaleDownThresh: 0.3, // Scale down when queue is 30% full
			CheckInterval:   s.cfg.Workers.ScaleCheckInterval,
		}

		s.logger.WithFields(map[string]interface{}{
			"min_workers":       minWorkers,
			"max_workers":       maxWorkers,
			"scale_up_thresh":   autoScalerConfig.ScaleUpThresh,
			"scale_down_thresh": autoScalerConfig.ScaleDownThresh,
		}).Info("Configuring worker pool auto-scaling")

		autoScaler := replication.NewAutoScaler(pool, autoScalerConfig, s.logger)
		autoScaler.Start(s.ctx)

		// Store autoscaler for later use
		s.autoScaler = autoScaler
	}

	return pool
}

// Enhanced shutdown with graceful job completion
func (s *Server) gracefulShutdown(ctx context.Context) error {
	s.logger.Info("Starting graceful shutdown")

	// Stop accepting new jobs
	s.logger.Info("Stopping job acceptance")

	// Wait for running jobs to complete (with timeout)
	s.logger.Info("Waiting for running jobs to complete")

	// Stop worker pool
	s.workerPool.Stop()

	// Stop autoscaler if enabled
	if s.autoScaler != nil {
		s.autoScaler.Stop()
	}

	// Stop rate limiter cleanup if exists
	if s.rateLimiter != nil {
		s.rateLimiter.Stop()
	}

	s.logger.Info("Graceful shutdown complete")
	return nil
}

// Health check with detailed component status
func (s *Server) detailedHealthCheck() map[string]interface{} {
	health := map[string]interface{}{
		"status": "healthy",
		"components": map[string]interface{}{
			"server": map[string]interface{}{
				"status": "healthy",
			},
			"worker_pool": s.workerPoolHealth(),
			"job_manager": s.jobManagerHealth(),
			"registries":  s.registriesHealth(),
		},
	}

	// Determine overall status
	overallHealthy := true
	for _, component := range health["components"].(map[string]interface{}) {
		if compMap, ok := component.(map[string]interface{}); ok {
			if status, ok := compMap["status"].(string); ok && status != "healthy" {
				overallHealthy = false
				break
			}
		}
	}

	if !overallHealthy {
		health["status"] = "unhealthy"
	}

	return health
}

// workerPoolHealth checks worker pool health
func (s *Server) workerPoolHealth() map[string]interface{} {
	stats := s.workerPool.GetStats()

	status := "healthy"
	// Consider unhealthy if no workers or all workers are busy
	if stats.TotalWorkers == 0 {
		status = "unhealthy"
	} else if stats.ActiveWorkers == stats.TotalWorkers && stats.QueuedJobs > 0 {
		status = "degraded"
	}

	return map[string]interface{}{
		"status":         status,
		"total_workers":  stats.TotalWorkers,
		"active_workers": stats.ActiveWorkers,
		"queued_jobs":    stats.QueuedJobs,
	}
}

// jobManagerHealth checks job manager health
func (s *Server) jobManagerHealth() map[string]interface{} {
	// Get job counts
	allJobs := s.jobManager.ListJobs("", "")
	runningJobs := s.jobManager.ListJobs("", JobStatusRunning)
	failedJobs := s.jobManager.ListJobs("", JobStatusFailed)

	status := "healthy"
	// Consider degraded if too many failed jobs
	failureRate := float64(len(failedJobs)) / float64(len(allJobs))
	if len(allJobs) > 0 && failureRate > 0.5 {
		status = "degraded"
	}

	return map[string]interface{}{
		"status":       status,
		"total_jobs":   len(allJobs),
		"running_jobs": len(runningJobs),
		"failed_jobs":  len(failedJobs),
	}
}

// registriesHealth checks configured registries health
func (s *Server) registriesHealth() map[string]interface{} {
	registryCount := 0
	if s.cfg.ECR.AccountID != "" {
		registryCount++
	}
	if s.cfg.GCR.Project != "" {
		registryCount++
	}
	registryCount += len(s.cfg.Registries.Registries)

	status := "healthy"
	if registryCount == 0 {
		status = "warning"
	}

	return map[string]interface{}{
		"status":           status,
		"configured_count": registryCount,
	}
}

// Add these fields to the Server struct (to be added to server.go):
// autoScaler  *replication.AutoScaler
// rateLimiter *RateLimiter

// GetJobManager returns the job manager (for testing)
func (s *Server) GetJobManager() *JobManager {
	return s.jobManager
}

// GetWorkerPool returns the worker pool (for testing)
func (s *Server) GetWorkerPool() *replication.WorkerPool {
	return s.workerPool
}

// GetMetricsRegistry returns the metrics registry (for testing)
func (s *Server) GetMetricsRegistry() *MetricsRegistry {
	return s.metricsRegistry
}

// GetJobCount returns the total number of jobs
func (jm *JobManager) GetJobCount() int {
	jm.jobsMutex.RLock()
	defer jm.jobsMutex.RUnlock()
	return len(jm.jobs)
}

// Enhanced configuration validation
func (s *Server) validateConfiguration() error {
	// Validate server configuration
	if s.cfg.Server.Port <= 0 || s.cfg.Server.Port > 65535 {
		return fmt.Errorf("invalid server port: %d", s.cfg.Server.Port)
	}

	// Validate worker configuration
	if s.cfg.Workers.ServeWorkers < 0 {
		return fmt.Errorf("invalid worker count: %d", s.cfg.Workers.ServeWorkers)
	}

	// Validate TLS configuration if enabled
	if s.cfg.Server.TLSEnabled {
		if s.cfg.Server.TLSCertFile == "" {
			return fmt.Errorf("TLS enabled but no certificate file specified")
		}
		if s.cfg.Server.TLSKeyFile == "" {
			return fmt.Errorf("TLS enabled but no key file specified")
		}
	}

	// Validate API key if authentication is enabled
	if s.cfg.Server.APIKeyAuth && s.cfg.Server.APIKey == "" {
		return fmt.Errorf("API key authentication enabled but no API key configured")
	}

	return nil
}

// RequestMetrics tracks HTTP request metrics
type RequestMetrics struct {
	Method     string
	Path       string
	StatusCode int
	Duration   float64
	Error      error
}

// RecordRequest records an HTTP request in metrics
func (s *Server) RecordRequest(metrics RequestMetrics) {
	// Record in Prometheus metrics
	s.metricsRegistry.RecordHTTPRequest(
		metrics.Method,
		metrics.Path,
		fmt.Sprintf("%d", metrics.StatusCode),
		metrics.Duration,
	)

	// Log if error occurred
	if metrics.Error != nil {
		s.logger.WithFields(map[string]interface{}{
			"method":      metrics.Method,
			"path":        metrics.Path,
			"status_code": metrics.StatusCode,
			"duration_ms": metrics.Duration,
			"error":       metrics.Error.Error(),
		}).Error("HTTP request failed")
	} else {
		s.logger.WithFields(map[string]interface{}{
			"method":      metrics.Method,
			"path":        metrics.Path,
			"status_code": metrics.StatusCode,
			"duration_ms": metrics.Duration,
		}).Debug("HTTP request completed")
	}
}
